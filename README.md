# code_for_Ndufs6_mus
## Data analysis:
## 1. Data processing. The processing pipeline for analyzing raw paired-end sequencing data involves several specialized tools tailored for quality control, base trimming, accurate alignment, and comprehensive genomic analysis. Initially, FastQC (v0.11.8) is used to conduct a quality assessment of the raw data to identify potential issues. Adapter sequences and low-quality bases are then removed using Cutadapt (v2.10) and Trimmomatic (v0.39), with specific adapters tailored to different libraries. The trimmed reads are aligned to the mouse reference genome (Mus_musculus.GRCm39.dna.primary_assembly.fa) using STAR (v2.7.3a) to ensure precise mapping. Post-alignment tasks, including sorting and indexing of the mapped reads, are managed using Samtools (v1.7). Finally, transcript isoform quantification is performed using Cufflinks (v2.2.1) to understand gene expression levels. This comprehensive pipeline ensures data integrity and accuracy throughout the analysis process.
## 2. Cutadapt for adapter removing. Cutadapt is utilized to remove adapter sequences, which are short fragments of DNA ligated to the ends of sequenced fragments during library preparation. Each library type may require the removal of specific adapters tailored to its preparation protocol. By accurately identifying and excising these adapter sequences, Cutadapt ensures that the resulting data is free from contamination, thereby improving the quality and reliability of subsequent analyses.
## 3. Data Cleaning with Trimmomatic: Trimmomatic is used to remove adapter sequences, trim low-quality bases, and filter out poor-quality reads from raw sequencing data. This step is crucial for improving read quality, which is essential for accurate alignment and downstream analysis.
bash
```
for i in $(cat $path_raw_read/samplelist.txt); do
    trimmomatic PE -threads 5 \
        $path_raw_cutadapt/${i}_cutadapt_R1.fastq \
        $path_raw_cutadapt/${i}_cutadapt_R2.fastq \
        -baseout $path_raw_trimmomatic/${i}_cutadapt_trim.fastq \
        LEADING:30 TRAILING:30 SLIDINGWINDOW:4:15 AVGQUAL:20 MINLEN:20
done
```
## 4. Alignment of Cleaned Reads to a Reference 
### 4.1 STAR indexing
First, we generate the genome index using STAR. This step prepares the reference genome for efficient alignment.
bash
```
STAR --runMode genomeGenerate \
     --runThreadN 5 \
     --genomeFastaFiles ./Homo_sapiens.GRCh38.dna.primary_assembly.fa \
     --genomeDir ./STAR_index/ \
     --sjdbGTFfile ./Homo_sapiens.GRCh38.111.gtf \
     --sjdbOverhang 149
```
### 4.2 STAR mapping
Next, we align the cleaned reads to the reference genome using STAR. This step produces sorted BAM files and generates various output files for downstream analysis.
```
for i in $(cat $path_raw_read/samplelist.txt); do
    STAR --runThreadN 10 \
         --genomeDir /home/boot/qiangsu/ref/STAR_index/ \
         --readFilesIn /home/boot/qiangsu/drug_pool/TCM_process_data/trimmed_data/${i}_trim_1P.fastq /home/boot/qiangsu/drug_pool/TCM_process_data/trimmed_data/${i}_trim_2P.fastq \
         --sjdbOverhang 149 \
         --outFileNamePrefix /home/boot/qiangsu/drug_pool/TCM_process_data/sam_data/${i}- \
         --outSAMtype BAM SortedByCoordinate \
         --twopassMode Basic \
         --quantMode TranscriptomeSAM GeneCounts \
         --chimOutType Junctions SeparateSAMold \
         --chimSegmentMin 10
done
```
## 5. Converting SAM to BAM with Samtools
We use Samtools to convert the SAM files generated by STAR into BAM files. This step also sorts the BAM files by coordinate.
bash
```
for i in $(cat $path_raw_read/samplelist.txt); do
    samtools sort -@ 10 -o ${bam_dir}/${i}_cutadapt_trim.bam ${sam_dir}/${i}_cutadapt_trim.sam
done
echo "Samtools conversion done"
```
## 6. Indexing BAM Files with Samtools
Next, we index the sorted BAM files to facilitate rapid access to specific genomic regions.
bash
```
for i in $(cat $path_raw_read/samplelist.txt); do
    samtools index -@ 10 ${bam_dir}/${i}_cutadapt_trim.bam
done
```
## 7. Transcript Assembly with Cufflinks
Finally, we use Cufflinks to assemble transcripts from the aligned reads. This step generates transcript abundance estimates and can be used for differential expression analysis.
bash
```
for i in $(cat $path_raw_read/samplelist.txt); do
    cufflinks -p 10 \
              --library-type fr-firststrand \
              -G /home/data/qs/data/reference_isoform/mus_ref/Mus_musculus.GRCm39.112.chr.gtf \
              -b /home/data/qs/data/reference_isoform/mus_ref/Mus_musculus.GRCm39.dna.primary_assembly.fa \
              -o ./cufflinks_result_nonbiascorrect_musHD_COX-1/${i} \
              /home/data/qs/HGC20231021002-0004/trimmed_data/cufflinks_result_HD/${i}_Aligned.sortedByCoord.out.bam
done
```
## 8. Collecting Cufflinks Transcript Data Across All Samples 
After assembling transcripts for each sample, we need to collect and combine the transcript data. This step is performed using a custom Python script named cufflinks_data_combined.py.
```
python cufflinks_data_combined.py
```
## 9. Differential Expression Analysis with DESeq2
Next, we perform differential expression analysis using DESeq2. This R script, DEseq2_isoform_cufflinks.R, identifies differentially expressed transcripts between conditions.
source("DEseq2_isoform_cufflinks.R")

## 10.  Functional Enrichment Analysis with GO and KEGG
Finally, we perform functional enrichment analysis to interpret the biological significance of the differentially expressed transcripts. This step uses the R script GO_KEGG_cufflinks.R.
source("GO_KEGG_cufflinks.R")

